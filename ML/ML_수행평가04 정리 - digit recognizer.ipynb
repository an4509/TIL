{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "challenging-september",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/digit/train.csv')\n",
    "display(df, df.shape)\n",
    "\n",
    "# 데이터의 명세를 잘 파악해야 함.\n",
    "# 각 픽셀의 값은 0 ~ 255 사이의 값을 가질 수 있음.\n",
    "# 이 값이 크면 클 수록 어두운 색상임.\n",
    "# 어떻게 알 수 있음? kaggle Data Description\n",
    "\n",
    "# 이상치와 결측치가 없음\n",
    "\n",
    "# 이미지 확인\n",
    "img_data = df.drop('label', axis=1, inplace=False).values # 2차원 numps로 변환\n",
    "\n",
    "fig = plt.figure()\n",
    "fig_arr = []  # 10개의 subplot을 만들고 그 각각의 subplot을 list에 저장\n",
    "\n",
    "for n in range(10):\n",
    "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
    "    fig_arr[n].imshow(img_data[n].reshape(28,28), cmap='Greys', \n",
    "                      interpolation='nearest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 흑백 이미지로 바꿔서도 할 수 있음.\n",
    "# 흑백으로 처리해서 하는것이 효율적이다.\n",
    "\n",
    "# 데이터 분할\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('label', axis=1, inplace=False),\n",
    "                 df['label'], test_size=0.3, random_state=0)\n",
    "\n",
    "# 정규화 (feature가 0~255 까지 이기 때문에 정규화 필요)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "sess = tf.Session()\n",
    "t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=10))\n",
    "t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=10))\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([784,10]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([10]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) # softmax activation function\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# parameter\n",
    "num_of_epoch = 1000\n",
    "batch_size = 100 # 한번에 읽어들일 학습할 데이터의 사이즈\n",
    "\n",
    "# 학습용 함수\n",
    "# cross validation을 하기 위해\n",
    "def run_train(sess, train_x, train_t):\n",
    "    print('### 학습 시작')\n",
    "    # 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(num_of_epoch):\n",
    "        total_batch = int(train_x.shape[0] / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]\n",
    "            _, loss_val = sess.run([train,loss], feed_dict={X:batch_x,\n",
    "                                                            T:batch_t})\n",
    "        if step % 100 == 0:\n",
    "            print('Loss: {}'.format(loss_val))\n",
    "    print('###학습 종료###')\n",
    "    \n",
    "# Accuracy 측정\n",
    "predict = tf.argmax(H,1) # axis 열방향으로 비교 1\n",
    "correct = tf.equal(predict, tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vanilla-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 학습 시작\n",
      "Loss: 1.9497268199920654\n",
      "Loss: 0.20953674614429474\n",
      "Loss: 0.16432689130306244\n",
      "Loss: 0.14341400563716888\n",
      "Loss: 0.1312403529882431\n",
      "Loss: 0.12324666976928711\n",
      "Loss: 0.11761331558227539\n",
      "Loss: 0.11341657489538193\n",
      "Loss: 0.11012786626815796\n",
      "Loss: 0.10743162035942078\n",
      "###학습 종료###\n",
      "### 학습 시작\n",
      "Loss: 2.478250741958618\n",
      "Loss: 0.23764991760253906\n",
      "Loss: 0.1871141940355301\n",
      "Loss: 0.16656982898712158\n",
      "Loss: 0.15700161457061768\n",
      "Loss: 0.15123291313648224\n",
      "Loss: 0.14714626967906952\n",
      "Loss: 0.14401841163635254\n",
      "Loss: 0.14150165021419525\n",
      "Loss: 0.13938194513320923\n",
      "###학습 종료###\n",
      "### 학습 시작\n",
      "Loss: 1.9044626951217651\n",
      "Loss: 0.1872226893901825\n",
      "Loss: 0.1546766608953476\n",
      "Loss: 0.13909298181533813\n",
      "Loss: 0.1297958791255951\n",
      "Loss: 0.1237330436706543\n",
      "Loss: 0.11955387145280838\n",
      "Loss: 0.11653917282819748\n",
      "Loss: 0.11426984518766403\n",
      "Loss: 0.11248742789030075\n",
      "###학습 종료###\n",
      "### 학습 시작\n",
      "Loss: 2.431135654449463\n",
      "Loss: 0.21728545427322388\n",
      "Loss: 0.19116386771202087\n",
      "Loss: 0.17515066266059875\n",
      "Loss: 0.16432525217533112\n",
      "Loss: 0.15682798624038696\n",
      "Loss: 0.15137313306331635\n",
      "Loss: 0.14715619385242462\n",
      "Loss: 0.14370958507061005\n",
      "Loss: 0.14076729118824005\n",
      "###학습 종료###\n",
      "### 학습 시작\n",
      "Loss: 1.9341397285461426\n",
      "Loss: 0.25636211037635803\n",
      "Loss: 0.21832036972045898\n",
      "Loss: 0.19946035742759705\n",
      "Loss: 0.18636342883110046\n",
      "Loss: 0.17608429491519928\n",
      "Loss: 0.16775177419185638\n",
      "Loss: 0.16090913116931915\n",
      "Loss: 0.1552039086818695\n",
      "Loss: 0.1503584384918213\n",
      "###학습 종료###\n",
      "측정한 각각의 결과값 : [0.91190475, 0.9071429, 0.9052721, 0.9052721, 0.90442175]\n",
      "최종 K-Fold 교차검증을 사용한 Accuracy : 0.906802773475647\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross Validation\n",
    "cv = 5  # Fold의 수\n",
    "results = [] # 각 Fold당 학습과 성능평가가 진행되는데 이때 계산된 성능평가 값을 저장\n",
    "\n",
    "# 훈련set과 검증set으로 나누기\n",
    "kf = KFold(n_splits=cv, shuffle=True)\n",
    "\n",
    "for training_idx, validation_idx in kf.split(x_data_train_norm):\n",
    "    training_x = x_data_train_norm[training_idx] \n",
    "    training_t = t_data_train_onehot[training_idx]\n",
    "    \n",
    "    val_x = x_data_train_norm[validation_idx]\n",
    "    val_t = t_data_train_onehot[validation_idx]\n",
    "    \n",
    "    # 학습\n",
    "    run_train(sess,training_x,training_t)\n",
    "    results.append(sess.run(accuracy, feed_dict={X:val_x, T:val_t}))\n",
    "    \n",
    "print('측정한 각각의 결과값 : {}'.format(results))\n",
    "print('최종 K-Fold 교차검증을 사용한 Accuracy : {}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "upper-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 학습 시작\n",
      "Loss: 1.7512856721878052\n",
      "Loss: 0.21291346848011017\n",
      "Loss: 0.17318828403949738\n",
      "Loss: 0.16055148839950562\n",
      "Loss: 0.15405334532260895\n",
      "Loss: 0.15000413358211517\n",
      "Loss: 0.14719103276729584\n",
      "Loss: 0.1450308859348297\n",
      "Loss: 0.1432146281003952\n",
      "Loss: 0.14158335328102112\n",
      "###학습 종료###\n",
      "우리 Model의 최종 정확도는 : 0.9128571152687073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        num0       0.95      0.95      0.95      1242\n",
      "        num1       0.95      0.97      0.96      1429\n",
      "        num2       0.90      0.89      0.90      1276\n",
      "        num3       0.90      0.89      0.90      1298\n",
      "        num4       0.91      0.91      0.91      1236\n",
      "        num5       0.87      0.88      0.87      1119\n",
      "        num6       0.93      0.95      0.94      1243\n",
      "        num7       0.95      0.92      0.93      1334\n",
      "        num8       0.87      0.87      0.87      1204\n",
      "        num9       0.88      0.90      0.89      1219\n",
      "\n",
      "    accuracy                           0.91     12600\n",
      "   macro avg       0.91      0.91      0.91     12600\n",
      "weighted avg       0.91      0.91      0.91     12600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "run_train(sess,x_data_train_norm,t_data_train_onehot)\n",
    "final_accuracy = sess.run(accuracy, feed_dict={X:x_data_test_norm,\n",
    "                                               T:t_data_test_onehot})\n",
    "print('우리 Model의 최종 정확도는 : {}'.format(final_accuracy))\n",
    "\n",
    "# 만약 Precision, Recall, F1, Accuracy를 각각 구하고 싶으면?\n",
    "target_names = ['num0', 'num1', 'num2', 'num3', 'num4', 'num5',\n",
    "                'num6', 'num7', 'num8', 'num9']\n",
    "\n",
    "\n",
    "print(classification_report(t_data_test,\n",
    "                      sess.run(predict, feed_dict={X:x_data_test_norm}),\n",
    "                      target_names = target_names)) # 인자 순서 : 1. 정답(one-hot 안된 형태), 2.예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "negative-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출하기\n",
    "\n",
    "# test data 불러오기\n",
    "df_test = pd.read_csv('./data/digit/test.csv')\n",
    "test_x_data = df_test.values.reshape(-1,784)\n",
    "\n",
    "# 정규화\n",
    "test_X_data_norm = scaler.transform(test_x_data)\n",
    "\n",
    "# Test data\n",
    "test_result = sess.run(predict, feed_dict={X: test_X_data_norm})\n",
    "\n",
    "# submission\n",
    "submission = pd.read_csv('./data/digit/sample_submission.csv')\n",
    "submission['Label'] = test_result\n",
    "submission.to_csv('./data/digit/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env]",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
