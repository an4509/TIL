# Tensorflow



## 연습해보기

```python
import tensorflow as tf

# 프로그래밍할 때 constant 잘 안씀! 하지만 예시를 위해 잠시 사용
node1 = tf.constant(10, dtype=tf.float32) # 실수표현할 때 32를 기본으로 함.
node2 = tf.constant(20, dtype=tf.float32) 

node3 = node1 + node2

# 그래프를 실행시키기 위해서는 session이라는게 필요(runner)
sess = tf.Session() # 2.x버전에서는 session이 삭제

print(sess.run(node3)) # 30.0
```



## Placeholder와 feed_dict의 개념

```python
# Data Flow Graph에 입력값을 주려면 어떻게 해야 하나요?
# placeholder를 이용
# placeholder 는 입력 parameter를 받아주는 바구니

import tensorflow as tf

node1 = tf.placeholder(dtype=tf.float32) 
node1 = tf.placeholder(dtype=tf.float32)

node3 = node1 + node2

sess = tf.Session()

result = sess.run(node3, feed_dict={node1 : 10, 
                                     node2 : 20}) # feed_dict로 데이터를 주는 것

print(result) # 30.0
```



## Simple Linear Regression 구현



### Training data set

* 데이터들을 한번에 계산을 해주기 위해 array를 사용하고, reshape으로 2차원 형태로 잡아줌.
* 입력값과 lable값을 입력
* print 해서 2차원 형태로 표현되는지 중간 확인.

```python
# 1. training data set
# python의 list로 training data를 표현할 수도 있지만, 
# numpy array로 표현하면 2차원으로 표현하기 쉬움
x_data = (np.array([1,2,3,4,5])).reshape(5,1) # 입력값 (x)
t_data = (np.array([3,5,7,9,11])).reshape(5,1) # lable (t) 

print(x_data)
```



### Placeholder

*  2가지 역할을 수행
  *  training data set을 받아들여서 모델을 학습하는 역할.
  * 내가 알고 싶은 x값을 prediction 하는 역할.
*  [None,1]이 오는 이유
  * column값 1은 고정값이기 때문에 변하면 안되어 1로 명시.
  * row값은 데이터의 개수이자, prediction 할 때의 값 1개가 오는 자리이기 때문에 None을 사용.
  *  None은 상관하지 않겠다는 뜻 

```python
 # shape을 통해 차원을 명시
X = tf.placeholder(shape=[None,1], dtype=tf.float32) 
T = tf.placeholder(shape=[None,1], dtype=tf.float32) 
```



### Weight & bias

* y = Wx + b은 결국  y = X dot W + b로 표현 ( X, W는 2차원 매트릭스로 표현)
* Variable은 값이 계속 변하는 node
* random값을 주어 최초 시작값 지정
  * W는 X와 행렬곱을 계산하기 위해 [1,1]로 지정

```python
W = tf.Variable(tf.random.normal([1,1]), name='weight')
b = tf.Variable(tf.random.normal([1]), name='bias')
```



### Hypothesis or predict model

* y = Wx + b => 2차원 행렬로 처리 => y = X dot W + b행렬곱이기 때문에 순서 조심.
*  순서는 X 다음 W로! 
* 행렬곱 연산해주는 함수 tf.matmul() 사용

```python
H = tf.matmul(X,W) + b 
```



###  loss function 정의

* W,b를 구하기 위해 평균제곱오차를 이용한 최소제곱법 구현
* error : H - T 
* square : 제곱해주는 함수 
* reduce_mean : 평균을 구하는 함수

```python
loss = tf.reduce_mean(tf.square(H - T))
```



### 학습과정 진행

* Gredient Descent : 알고리즘을 적용해서 갱신해주는 함수.
* ()안에 learning_rate 명시, loss를 미분해 나간다는 뜻으로 minimize().
* train node가 하는 일은 w와 b를 한번 학습해주는 것.
* 아직 반복설정된 것이 아님.

```python
train = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss)
```



### Session 설정

* variable을 쓰는 경우에는 초기화 작업이 필요.
* 초기화 작업 무조건 필요하나, 2.x 버전 넘어오면서 삭제됨.

```python
sess = tf.Session() # session 얻어오기
sess.run(tf.global_variables_initializer()) 
```



### 학습진행

* 반복학습을 진행 ( 1 epoch : training data set 전체를 이용하여 1번 학습하는 것).

```python
for step in range(30000):  # 3000 epoch 반복 / 내가 가지고 있는 데이터양에 따라 epoch 수를 조정. 데이터가 크면 epoch를 크게 할 수 없음. 
    
    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], feed_dict={X : x_data, T : t_data})  # _ 를 쓰는 이유는 결과값은 의미가 없어임. 중요한건 w와 b의 값
    
    if step % 3000 == 0: 
        print('W : {}, b : {}, loss : {}'.format(W_val, b_val, loss_val))
```



### Prediction(예측)

* 학습이 종료된 후 최적의 W와 b가 계산되고 이를 이용한 model이 완성

```python
result = sess.run(H, feed_dict={X : [[9]]}) # 2차원으로 들어가기 위해서 중첩리스트
print('예측값은 : {}'.format(result))
```



### 전체코드

```python
import numpy as np
import pandas as pd
import tensorflow as tf

# 1. training data set
x_data = (np.array([1,2,3,4,5])).reshape(5,1) 
t_data = (np.array([3,5,7,9,11])).reshape(5,1) # lable

# print(x_data)

# 2. placeholder
X = tf.placeholder(shape=[None,1], dtype=tf.float32)
T = tf.placeholder(shape=[None,1], dtype=tf.float32) 

# 3. Weight & bias 
W = tf.Variable(tf.random.normal([1,1]), name='weight')  
b = tf.Variable(tf.random.normal([1]), name='bias')

# 4. Hypothesis or predict model
H = tf.matmul(X,W) + b 

# 5. W,b를 구하기 위해 평균제곱오차를 이용한 최소제곱법을 통해 loss function 정의
loss = tf.reduce_mean(tf.square(H - T))

# 6. train 학습과정 진행
train = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss) 

# 7. session & variable을 쓰는 경우에는 초기화 작업이 필요
sess = tf.Session() # session 얻어오기
sess.run(tf.global_variables_initializer())

# 8. 학습을 진행
for step in range(30000): 
    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], feed_dict={X : x_data, T : t_data}) 
    
    if step % 3000 == 0: 
        print('W : {}, b : {}, loss : {}'.format(W_val, b_val, loss_val))
        

# 9. 학습이 종료된 후 최적의 W와 b가 계산되고 이를 이용한 model이 완성
#    prediction(예측)
result = sess.run(H, feed_dict={X : [[9]]}) 

print('예측값은 : {}'.format(result))    
```



# Python으로 코드구현



## training data set

* 행렬곱 연산을 위해 2차원으로 구성

```python
x_data = np.array([1,2,3,4,5]).reshape(5,1)
t_data = np.array([3,5,7,9,11]).reshape(5,1)
```



## Weight & bias 설정

* 마찬가지로 행렬곱 연산을 위해 W는 2차원, b는 broadcasting이 되기 때문에 scala로 표현

```python
W = np.random.rand(1,1)
b = np.random.rand(1)
```



## Hypothesis

* 모델 학습이 끝나 W,b를 구한 뒤 사용할 함수를 구현
* dot은 행렬곱 연산 함수

```python
def predict(x):
    y = np.dot(x,W) + b  # y = x dot W + b
    return y
```



## Loss function

* 원래는 w,b를 인자로 잡아야 하는데 미분처리를 위해서 input_obj를 인자로 씀
* input_obj 안에 리스트 형태로 w,b가 들어옴

```python
def loss_func(input_obj):
    # input_obj : [W, b]
    input_W = input_obj[0]
    input_b = input_obj[1]
    
    y = np.dot(x_data, input_W) + input_b  # 가설세운 것임. 가설이 있어야 loss 함수를 구할 수 있음
    return np.mean(np.power((t_data - y),2)) # loss function
```



## 편미분을 위한 함수

* 따로 작성해둔 편미분 코드를 불러오기

```python
def numerical_derivative(f,x):
    # f : 미분하려고 하는 다변수 함수
    # x : 모든 값을 포함하는 numpy array ex) f`(1.0, 2.0) = (8.0, 15.0)
    #     [W,b]에 대해 편미분
    delta_x = 1e-4
    derivative_x = np.zeros_like(x)   # [0.0]  # 결과 저장용
    # np.zeros_like : ~처럼 만들어서 0으로 채우세요
    
    it = np.nditer(x, flags=['multi_index'])  # np array 반복할 때 사용 
    # flags를 사용하는 이유는 3개 이상으로 변수가 주어질 때 매트릭스로 들어 올 수 있기 때문
    
    while not it.finished:
        
        idx = it.multi_index  # 현재의 iterator의 index를 추출 => tuple형태로
#         print('현재의 idx 값은 : {}'.format(idx))
        
        tmp = x[idx]  # 현재 index의 값을 잠시 보존. 
                      # delta_x를 이용한 값으로 ndarray를 수정한 후 편미분을 계산
                      # 함수값을 계산한 후 원상복구를 해 줘야 다음 독립변수에 대한
                      # 편미분을 정상적으로 수행할 수 있음.
#         print('현재 temp : {}'.format(tmp))
        
        x[idx] = tmp + delta_x
        fx_plus_delta = f(x)   # f([1.00001, 2.0]) => f(x + delta_x)
        
        x[idx] = tmp - delta_x
        fx_minus_delta = f(x)   # f([0.99999, 2.0]) => f(x - delta_x)
        
        derivative_x[idx] = (fx_plus_delta - fx_minus_delta) / (2 * delta_x)
        
        x[idx] = tmp # 다음 독립변수 편미분을 위해 원상복귀
        
        it.iternext()
        
    return derivative_x
```



## Learning Rate 설정 및 학습 진행

* ravel은 1차원 벡터로 만들어주는 함수.
* axis는 가로방향으로 해야 [W b]로 붙여짐.

```python
learning_rate = 1e-4

for step in range(300000):
    input_param = np.concatenate((W.ravel(), b.ravel()), axis=0)
    derivative_result = learning_rate * numerical_derivative(loss_func, input_param)
    
    # W,b를 갱신
    W = W - derivative_result[:1].reshape(1,1)
    b = b - derivative_result[1:]
    
    if step % 30000 ==0:
        print('W : {}, b : {}'.format(W,b))
```



## 전체코드

```python
# SImple Linear Regression을 python으로 구현하기

import numpy as np

# 1. training data set
# 똑같이 행렬곱 연산을 위해 2차원으로 구성
x_data = np.array([1,2,3,4,5]).reshape(5,1)
t_data = np.array([3,5,7,9,11]).reshape(5,1)

# 2. Weight & bias
# 위와 동일함
W = np.random.rand(1,1)
b = np.random.rand(1)

# 3. Hypothesis
# 모델 학습이 끝나 W,b를 구한 뒤 사용할 함수를 구현
# dot은 행렬곱 연산 함수
def predict(x):
    y = np.dot(x,W) + b  # y = x dot W + b
    return y

# 4. loss function
# 원래는 w,b를 인자로 잡아야 하는데 미분처리를 위해서 input_obj를 인자로 씀
def loss_func(input_obj):
    # input_obj : [W, b]
    input_W = input_obj[0]
    input_b = input_obj[1]
    
    y = np.dot(x_data, input_W) + input_b  # 가설세운 것임. 가설이 있어야 loss 함수를 구할 수 있음
    return np.mean(np.power((t_data - y),2)) # loss function

# 5. 편미분을 위한 함수
def numerical_derivative(f,x):
    # f : 미분하려고 하는 다변수 함수
    # x : 모든 값을 포함하는 numpy array ex) f`(1.0, 2.0) = (8.0, 15.0)
    #     [W,b]에 대해 편미분
    delta_x = 1e-4
    derivative_x = np.zeros_like(x)   # [0.0]  # 결과 저장용
    # np.zeros_like : ~처럼 만들어서 0으로 채우세요
    
    it = np.nditer(x, flags=['multi_index'])  # np array 반복할 때 사용 
    # flags를 사용하는 이유는 3개 이상으로 변수가 주어질 때 매트릭스로 들어 올 수 있기 때문
    
    while not it.finished:
        
        idx = it.multi_index  # 현재의 iterator의 index를 추출 => tuple형태로
#         print('현재의 idx 값은 : {}'.format(idx))
        
        tmp = x[idx]  # 현재 index의 값을 잠시 보존. 
                      # delta_x를 이용한 값으로 ndarray를 수정한 후 편미분을 계산
                      # 함수값을 계산한 후 원상복구를 해 줘야 다음 독립변수에 대한
                      # 편미분을 정상적으로 수행할 수 있음.
#         print('현재 temp : {}'.format(tmp))
        
        x[idx] = tmp + delta_x
        fx_plus_delta = f(x)   # f([1.00001, 2.0]) => f(x + delta_x)
        
        x[idx] = tmp - delta_x
        fx_minus_delta = f(x)   # f([0.99999, 2.0]) => f(x - delta_x)
        
        derivative_x[idx] = (fx_plus_delta - fx_minus_delta) / (2 * delta_x)
        
        x[idx] = tmp # 다음 독립변수 편미분을 위해 원상복귀
        
        it.iternext()
        
    return derivative_x

# learning rate 설정
learning_rate = 1e-4

# 학습을 진행
# ravel은 1차원 벡터로 만들어주는 함수
# axis는 가로방향으로 해야 [W b]로 붙여짐
for step in range(300000):
    input_param = np.concatenate((W.ravel(), b.ravel()), axis=0)
    derivative_result = learning_rate * numerical_derivative(loss_func, input_param)
    
    # W,b를 갱신
    W = W - derivative_result[:1].reshape(1,1)
    b = b - derivative_result[1:]
    
    if step % 30000 ==0:
        print('W : {}, b : {}'.format(W,b))
```



# Library로 코드 구현

* sklearn library로 쉽게 코드가 구현.
* 강의 때는 코드확인용으로 사용 예정!

```python
# sklearn을 사용하기 위해서는 설치가 필요
# 아나콘다에서 pip install sklearn

import numpy as np
from sklearn import linear_model

# 1. training data set
# 똑같이 행렬곱 연산을 위해 2차원으로 구성
x_data = np.array([1,2,3,4,5]).reshape(5,1)
t_data = np.array([3,5,7,9,11]).reshape(5,1)

# 2. linear regression model을 생성
# Hypothesis 생성
model = linear_model.LinearRegression()

# 3. 학습진행
# fit이라는 함수로 학습진행
model.fit(x_data, t_data)

# 4. Weight & bias를 알아보기
print('W : {}, b : {}'.format(model.coef_, model.intercept_))

# 5. predict
print(model.predict([[9]]))
```

