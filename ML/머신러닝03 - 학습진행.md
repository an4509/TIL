# 학습진행

> 학습 데이터셋(Training Data Set)안에 입력값(Feature) + 정답(Lable)이 있으면 학습진행이 됨. 
>
> 학습진행에 대해 알아보기.



## 학습(Learning)

> Classical Linear Regression Model (고전적 선형 회귀 모델)을 이용.
>
> y = ax + b



* y = Wx + b
* weight(가중치), bias
* 초기에 W,b는 랜덤이나 점점 데이터를 가장 잘 표현하는 값을 찾아가는 과정

```python
y = wx + b (우리의 가설)

실제값 : T
가설에 의해 계산된 값 : Y

오차(error) : 실제값과 가설에 의해 계산된 값의 차이
error = t-y = t - (Wx + b)

모델을 완성하기 위해 데이터의 error의 합이 최소가 되는 가중치(W)와 bias를 찾아야함.

1. 절대값을 이용해서 error의 합을 구함. -> 문제가 있음.
2. error 값을 제곱해서 평균을 구하기 (평균제곱오차). 
이를 수식을 만들어 찾기 위한 함수 -> 손실함수(loss function)
```



![](md-images/%ED%95%99%EC%8A%B5%20%EA%B7%B8%EB%9E%98%ED%94%84.PNG)



## 손실함수(Loss Function)

> 또는 비용함수 (Cost Function) 로도 쓰임.



* Training Data set의 정답(t)와 입력 x에 대한 계산값 y(모델의 예측값)의 차이를 모두 더해 수식으로 나타낸 식.
* MSE(평균제곱오차)를 이용해서 함수를 구하는 방법을 최소제곱법이라 함.
* 최소제곱법을 이용해서 만들어진 loss function의 값이 최소가 되게 하는 w와 b를 찾을 것임. (학습과정)
* 항상 loss function이 MSE와 같지는 않음.
* 결국 w에 대한 2차함수 형태.
* loss function의 값이 최소가 되게하는 w를 찾기 위해 경사하강법(Gradient Descent Algorithm)을 사용



### 경사하강법(Gradient Descent Algorithm)

* loss function을 미분한 값이 0인 지점을 찾는 것.
* W` = w - a (learning rate)* de(w,b)/dw
* learning rate는 정해져있지 않고 우리가 최적의  값을 찾아야함.
* 이러한 과정의 반복횟수를 -> 1 epoch



## 정리

* 우리의 예제는 독립변수가 1개인 Simple Linear Regression
  * Predict Model(예측모델)
  * 예측값(y), 입력값(x)
  * y = Wx + b
  * 우리는 최적의 (w,b) 값을 구해야함.
* 최적의 (w,b) 값을 구하기 위해서 Loss Function을 도입.
  * Loss Function은 최소제곱법으로 만듦.
  * 최소제곱법 안에는 MSE가 포함
  * Gredient Descent 알고리즘을 이용해서 최적의 w와 b를 찾음.



![](md-images/%ED%95%99%EC%8A%B5-%EC%A0%95%EB%A6%AC.PNG)



# Tensorflow

> 숫자연산을 위한 오픈 소스 Library.



* Node와 Edge로 구성된 방향성있는 Graph 만들 수 있음.
  * Node는 수치연산과 데이터 입출력을 담당.
  * Edge는 데이터를 실어 나르는 역할.
  * 방향성이 있다는 뜻은 데이터가 한 방향으로 흐른다는 뜻.
  * Tensor : 동적크기의 다차원 배열 (numpy의 다차원 array와 유사)
* 전체적인 Graph 구조를 먼저 만들고 필요에 따라 특정 node를 실행시키는 구조.



```python
# Tensorflow를 이용해서 배운 이론을 실제로 구현해 보아요
# Tensorflow는 Google이 만든 Deep Library
# Tensorflow는 1.x버전과 2.x버전으로 나뉘어져요
# 2019년 10월 Tensorflow 2.x버전이 정식으로 release
# 1.x버전은 low level의 코딩이 필요! (이론을 공부, 학습)
# 단점은 일반성이 떨어짐
# 2.x버전은 상위 API(Keras)가 기본으로 포함. => 구현이 쉬워졌음
# 사용하기 위해서 라이브러리부터 설치 (파이썬 3.7버전에서 가능)


import tensorflow as tf
print(tf.__version__)  # 1.15.0

node1 = tf.constant('Hello World')

print(node1)  # Tensor("Const_1:0", shape=(), dtype=string)
              # 실행이 아니라 안에 tensor의 정보가 나옴.

# 그래프를 실행하려면 1.x버전에서는 session이 필요
# session은 그래프안의 특정 노드를 실행시킬 수 있음.

sess = tf.Session()

print(sess.run(node1))  # b'Hello World'

# 앞의 b는 bite string 표시. 없애주려면 decode함수 사용

print(sess.run(node1).decode()) # Hello World

# 하지만 숫자 연산을 위한 라이브러리기 때문에
# 보통 문자열보다는 수치가 들어감.
```



* 수치예문 만들기.

```python
import tensorflow as tf

node1 = tf.constant(10, dtype=tf.float32)
node2 = tf.constant(30, dtype=tf.float32)

node3 = node1 + node2

# session은 tensorflow 그래프를 실행시키기 위해서 필요!
# 1.x버전에서만 사용. 2.x버전에서는 삭제

sess = tf.Session()

print(sess.run([node3, node1]))  # [40.0, 10.0]
```

