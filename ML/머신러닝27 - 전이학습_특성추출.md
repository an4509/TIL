# 전이학습

**전이학습이 왜 필요한가?**

* 기존 CNN을 사용하면 GPU 없이 CPU로 처리하면 100시간을 쉽게 넘어감

* 학습에 상당히 오랜시간이 소요 -> accuracy를 확인한 후 hyper parameter를 조절 -> 다시 학습

* 이 문제를 해결하기 위한 방법이 전이 학습 (transfer train)이고 이를 위해 pretrained network를 사용.



**개념**

* Image net에서 훈련된 모델(Pretrained Network)을 가져다 이용하는 학습방식.
  * 전통적인 모델 - ` VGG16`, `VGG19`
  * MS - `resnet`
  * google - `Inception`
  * `mobilenet` - 상대적으로 빠르게 학습이 가능 함.

  * `efficientnet` - 모델 1~6까지 있으며 버전이 높아질 수록 layer수가 많아지며 학습 시간이 오래걸림. 효율이 좋음.



**Pretrained Network란?**

* filter의 weight가 최적화되어 이미 설정되어 있고, cov2 pooling 작업이 다 되어 있는 model.

* 마치 다른사람이 만들어둔 필터를 가져다 쓰는 느낌



**특징**

* 속도가 빠르며 높은 정확도를 낼 수 있음.

* 실무에서 사용하는 Image는 MIST처럼 단순한 이미지가 아닌 고해상도 컬러이미지가 대부분이기 떄문에 최소 5개의 convolution, pooling layer가 필요하고 fc layer안에 hidden layer도 1개 이상 필요함. 이를 구현할 수 있음.



## 코드 구현

```python
from tensorflow.keras.applications import VGG16

# 다른 pretrainde network 도 적용해보기

model_base = VGG16(weights='imagenet',
                   include_top=False,
                   input_shape=(150,150,3)) 
# weights : 여러개의 입력데이터셋에 대해서 어떤 트레이닝 데이터셋을 이용한 VGG16인지 명시해줘야함.
# include_top : conv와 pool과 DNN까지 포함할 것인지 True, False로 명시 
# input_shape : input 데이터셋의 형태 

model_base.summary()
```

* pretrainde network 종류 중 하나인 VVG16로 모델 만들어서 변수에 담아주기
* summary를 찍으면 layer들을 볼 수 있고 최종 shape을 확인할 수 있음.





```python
# 개와 고양이 training data set에 대한 feature map을 추출하기

import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_dir = '/content/drive/MyDrive/Machine Learning Colab/CAT_DOG/cat_dog_small'
train_dir = os.path.join(base_dir,'train')
validation_dir = os.path.join(base_dir,'validation')
# ImageDataGenrator을 사용할 때 데이터를 어떤 폴더에서 가져오는지 명시
# os는 경로를 만들어주기 위함

datagen = ImageDataGenerator(rescale=1/255)
batch_size=20
# RGB 값이 0 ~ 255 사이 값을 255로 나눠서 0~1사이 값으로 scaling 해주기
# batch size 정해서 20개씩 가져오기

def extract_feature(directory, sample_count):
# directory : 특정 폴더에 가서 이미지 가져오기 위해
# sample_count : 이미지 개수
  
  features = np.zeros(shape=(sample_count, 4,4, 512))
  # np.zeros 함수를 통해 우선 형태만 만들어 0으로 채워주고 이후 데이터 붙여주기
  # sample_count = 이미지 개수
  # VGG16에서 최종적으로 나오는 (None, 4, 4, 512)에서 shape 맞춰주기
  labels = np.zeros(shape=(sample_count,))

  generator = datagen.flow_from_directory(
      directory,
      target_size = (150,150),
      batch_size = batch_size,
      class_mode = 'binary'
  )

  i = 0

  for x_data_batch, t_data_batch in generator:
    feature_batch = model_base.predict(x_data_batch)
    features[i*batch_size:(i+1)*batch_size] = feature_batch
    labels[i*batch_size:(i+1)*batch_size] = t_data_batch

    i += 1
    if i * batch_size >= sample_count:
      break
  
  return features, labels

train_features, train_labels = extract_feature(train_dir, 2000)
validation_features, validation_labels = extract_feature(validation_dir, 1000)
```

```python
Found 2020 images belonging to 2 classes. 
Found 1000 images belonging to 2 classes.
```

* 미리 설정된 폴더 경로를 통해 데이터를 끌어오기
* Image data generator를 통해 이미지 데이터 처리해주기.
* `extract_feature`라는 함수를 만들어서 shape을 미리 만들어주고 slicing으로 데이터 채워넣기.
* train, validation 분리해서 feature과 label을 담아주기.



```python
train_features = np.reshape(train_features, (2000,4*4*512))
validation_features = np.reshape(validation_features, (1000,4*4*512))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout # flatten 도 dense로 처리
from tensorflow.keras.optimizers import Adam

model = Sequential()
model.add(Dense(256,
                activation='relu',
                input_shape=(4*4*512,)))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_features,
                    train_labels,
                    epochs=30,
                    batch_size=64,
                    validation_data=(validation_features, validation_labels))
```

* reshape을 통해 데이터 개수와 pixel 값에 맞춰 shape 조정해주기.
* Flatten으로 데이터 받아줄 수 있지만, Dense로도 대체 가능.
* 학습속도가 빠른 것을 볼 수 있음.











